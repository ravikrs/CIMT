package de.rwth.i9.cimt.test;

import java.io.File;
import java.io.IOException;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.apache.solr.client.solrj.SolrServerException;
import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
import org.apache.solr.core.CoreContainer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import uk.ac.shef.dcs.jate.JATEException;
import uk.ac.shef.dcs.jate.JATEProperties;
import uk.ac.shef.dcs.jate.app.AppParams;
import uk.ac.shef.dcs.jate.app.AppRAKE;
import uk.ac.shef.dcs.jate.model.JATEDocument;
import uk.ac.shef.dcs.jate.model.JATETerm;
import uk.ac.shef.dcs.jate.util.JATEUtil;

public class AppRake {
	private static final Logger LOG = LoggerFactory.getLogger(AppRake.class);
	private static int id = 0;

	public static List<JATETerm> rakeAlgo(String text) throws JATEException, IOException, SolrServerException {
		String workingDir = System.getProperty("user.dir");
		Path solrHome = Paths.get(workingDir, "testdata", "solr-testbed");
		String solrHomeDir = solrHome.toString();
		List<JATETerm> terms = new ArrayList<>();
		String solrCoreName = "ACLRDTEC";
		File lock = Paths.get(solrHome.toString(), solrCoreName, "data", "index", "write.lock").toFile();
		if (lock.exists()) {
			System.err.println("Previous solr did not shut down cleanly. Unlock it ...");
			lock.delete();
		}

		EmbeddedSolrServer server = null;
		try {
			CoreContainer solrContainer = new CoreContainer(solrHomeDir);
			solrContainer.load();

			server = new EmbeddedSolrServer(solrContainer, solrCoreName);

			JATEDocument jateDocument = new JATEDocument("sample" + String.valueOf(++id));
			jateDocument.setContent(text);
			jateDocument.setId(String.valueOf(id));

			JATEProperties jateProp = new JATEProperties();

			JATEUtil.addNewDoc(server, jateDocument.getId(), jateDocument.getId(), jateDocument.getContent(), jateProp,
					true);

			LOG.info("AppRAKE ranking and filtering ... ");
			Map<String, String> initParam = new HashMap<>();
			initParam.put(AppParams.PREFILTER_MIN_TERM_TOTAL_FREQUENCY.getParamKey(), "1");
			initParam.put(AppParams.CUTOFF_TOP_K_PERCENT.getParamKey(), "1");

			AppRAKE appRAKE = new AppRAKE(initParam);
			terms = appRAKE.extract(server.getCoreContainer().getCore(solrCoreName), jateProp);
			for (JATETerm term : terms) {
				System.out.println(term.getString() + "," + term.getScore());
			}

			LOG.info("complete ranking and filtering.");

			/**
			 * The sample results is consistent with original paper.
			 *
			 * The slight difference is caused by two reasons: 1) candidates are
			 * generated by NP chunker rather than stop words filtering; 2) in
			 * JATE 2.0, we do lemmetise/stemming in candidate terms analyser
			 * chain before actual scoring. So, terms may have higher or lower
			 * score than corresponding one in original paper if plural form
			 * exists, e.g., "set", "minimal supporting set", "system",
			 * "corresponding algorithm"
			 */
		} finally {
			// if (server != null) {
			// server.getCoreContainer().getCore(solrCoreName).close();
			// // server.getCoreContainer().shutdown();
			// server.close();
			// }
		}
		return terms;

	}
}
